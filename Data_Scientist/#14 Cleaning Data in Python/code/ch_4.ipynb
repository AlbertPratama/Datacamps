{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from thefuzz import process\n",
    "import recordlinkage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6, 9, 12]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# book = {\n",
    "#     'title': 'The Giver',\n",
    "#     'author': 'Lois Lowry',\n",
    "#     'rating': 4.13\n",
    "# }\n",
    "# book = book['rating' ] = 4.16\n",
    "# book['rating']\n",
    "\n",
    "# def add(x,y):\n",
    "#   return (x+y)\n",
    "\n",
    "# add(2,4)\n",
    "\n",
    "# def h_(houe):\n",
    "#   return houe * 60 *60\n",
    "\n",
    "# h_(8)\n",
    "\n",
    "\n",
    "# book = {\n",
    "#     'title': 'The Giver',\n",
    "#     'author': 'Lois Lowry',\n",
    "#     'rating': 4.13\n",
    "# }\n",
    "\n",
    "# book['format'] = 'paperback'\n",
    "# book['format']\n",
    "\n",
    "\n",
    "[ i *3 for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dob(n):\n",
    "  return n*2\n",
    "dob(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "pack = ['a','b']\n",
    "\n",
    "for i in pack:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class build:\n",
    "  def __init__(self, number):\n",
    "    self.number = number\n",
    "\n",
    "b=build(245)\n",
    "b.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch\n"
     ]
    }
   ],
   "source": [
    "boardgames = [\n",
    "    'Rivals for Catan',\n",
    "    '7 Wonders Duel',\n",
    "    'Carcassonne',\n",
    "    'Hive',\n",
    "]\n",
    "\n",
    "boardgames.append('patch')\n",
    "print(boardgames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_random(value):\n",
    "  return value\n",
    "\n",
    "return_random('two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(5) if i >=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3, 4}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1, 2, 3, 4}\n",
    "b = {3, 4, 5, 6}\n",
    "\n",
    "a.intersection(b)\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>      name  height\n",
    "0  Heather   160.3\n",
    "1    Chris   175.1\n",
    "2      Eva   165.4\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Transposing the last two letters of '___sign___' is the easiest way to get to '___sing___' - in the next exercise, you'll use edit distance at scale to remap categories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../datasets/banking_dirty.csv'\n",
    "s = pd.read_csv(file, header=None)\n",
    "# s = s.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 287 entries, 0 to 286\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   name    287 non-null    object\n",
      " 1   addr    287 non-null    object\n",
      " 2   city    287 non-null    object\n",
      " 3   phone   287 non-null    int64 \n",
      " 4   type    287 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 11.3+ KB\n"
     ]
    }
   ],
   "source": [
    "restaurants = pd.read_csv('../datasets/restaurants_L2.csv', usecols=lambda x: x != 'Unnamed: 0', nrows=287)\n",
    "restaurants.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>435 s. la cienega blv .</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>3102461501</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>art's delicatessen</td>\n",
       "      <td>12224 ventura blvd.</td>\n",
       "      <td>studio city</td>\n",
       "      <td>8187621221</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>campanile</td>\n",
       "      <td>624 s. la brea ave.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>2139381447</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fenix</td>\n",
       "      <td>8358 sunset blvd. west</td>\n",
       "      <td>hollywood</td>\n",
       "      <td>2138486677</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grill on the alley</td>\n",
       "      <td>9560 dayton way</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>3102760615</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>lillie langtry's</td>\n",
       "      <td>129 e. fremont st.</td>\n",
       "      <td>las vegas</td>\n",
       "      <td>7023857111</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>mandarin court</td>\n",
       "      <td>1510 e. flamingo rd.</td>\n",
       "      <td>las vegas</td>\n",
       "      <td>7027371234</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>margarita's mexican cantina</td>\n",
       "      <td>3120 las vegas blvd. s</td>\n",
       "      <td>las vegas</td>\n",
       "      <td>7027948200</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>mikado</td>\n",
       "      <td>3400 las vegas blvd. s</td>\n",
       "      <td>las vegas</td>\n",
       "      <td>7027917111</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>venetian</td>\n",
       "      <td>3713 w. sahara ave.</td>\n",
       "      <td>las vegas</td>\n",
       "      <td>7028764190</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name                       addr         city  \\\n",
       "0      arnie morton's of chicago   435 s. la cienega blv .   los angeles   \n",
       "1             art's delicatessen       12224 ventura blvd.   studio city   \n",
       "2                      campanile       624 s. la brea ave.   los angeles   \n",
       "3                          fenix    8358 sunset blvd. west     hollywood   \n",
       "4             grill on the alley           9560 dayton way   los angeles   \n",
       "..                           ...                        ...          ...   \n",
       "282             lillie langtry's        129 e. fremont st.     las vegas   \n",
       "283               mandarin court      1510 e. flamingo rd.     las vegas   \n",
       "284  margarita's mexican cantina    3120 las vegas blvd. s     las vegas   \n",
       "285                       mikado    3400 las vegas blvd. s     las vegas   \n",
       "286                     venetian       3713 w. sahara ave.     las vegas   \n",
       "\n",
       "          phone      type  \n",
       "0    3102461501  american  \n",
       "1    8187621221  american  \n",
       "2    2139381447  american  \n",
       "3    2138486677  american  \n",
       "4    3102760615  american  \n",
       "..          ...       ...  \n",
       "282  7023857111     asian  \n",
       "283  7027371234     asian  \n",
       "284  7027948200   mexican  \n",
       "285  7027917111     asian  \n",
       "286  7028764190   italian  \n",
       "\n",
       "[287 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `The cutoff point`\n",
    "In this exercise, and throughout this chapter, you'll be working with the __restaurants__ DataFrame which has data on various __restaurants__. Your ultimate goal is to create a restaurant recommendation engine, but you need to first clean your data.\n",
    "\n",
    "This version of __restaurants__ has been collected from many sources, where the __cuisine_type__ column is riddled with typos, and should contain only __italian__, __american__ and __asian__ cuisine types. There are so many unique categories that remapping them manually isn't scalable, and it's best to use string similarity instead.\n",
    "\n",
    "Before doing so, you want to establish the cutoff point for the similarity score using the __thefuzz__'s __process.extract()__ function by finding the similarity score of the most distant typo of each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import __process__ from __thefuzz__.\n",
    "- Store the unique __cuisine_types__ into __unique_types__.\n",
    "- Calculate the similarity of '___asian___', '___american___', and '___italian___' to all possible __cuisine_types__ using __process.extract()__, while returning all possible matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Question`\n",
    "Take a look at the output, what do you think should be the similarity cutoff point when remapping categories?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `80` 80 is that sweet spot where you convert all incorrect typos without remapping incorrect categories. Often times though, you may need to combine the techniques learned in chapter 2, especially since there could be strings that make it beyond our cutoff point, but are not actually a match!\n",
    "\n",
    "- 70\n",
    "- 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asian', 100), ('italian', 67), ('american', 62), ('mexican', 50), ('steakhouses', 40), ('cajun', 40), ('southwestern', 36), ('southern', 31), ('coffeebar', 26)]\n",
      "[('american', 100), ('mexican', 80), ('cajun', 68), ('asian', 62), ('italian', 53), ('southwestern', 49), ('southern', 38), ('coffeebar', 24), ('steakhouses', 21)]\n",
      "[('italian', 100), ('asian', 67), ('american', 53), ('mexican', 43), ('cajun', 33), ('southwestern', 33), ('steakhouses', 33), ('southern', 27), ('coffeebar', 12)]\n"
     ]
    }
   ],
   "source": [
    "# Import process from thefuzz\n",
    "from thefuzz import process\n",
    "\n",
    "# Store the unique values of cuisine_type in unique_types\n",
    "unique_types = restaurants['type'].unique()\n",
    "\n",
    "# Calculate similarity of 'asian' to all values of unique_types\n",
    "print(process.extract('asian', unique_types, limit=len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'american' to all values of unique_types\n",
    "print(process.extract('american', unique_types, limit=len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'italian' to all values of unique_types\n",
    "print(process.extract('italian', unique_types, limit=len(unique_types)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Minimum Edit Distance__: You discovered that this metric measures the least number of operations (insertion, deletion, substitution, transposition) required to transform one string into another. For instance, transforming \"intention\" into \"execution\" involves a series of steps, with each operation counting towards the total edit distance.\n",
    "\n",
    "- __String Comparison with__ __thefuzz__: You explored how to use the __thefuzz__ package for string comparison, focusing on the WRatio function to compute similarity scores between strings. This method assigns scores ranging from 0 (not similar) to 100 (exact match), offering a robust way to compare strings with partial matches or different orderings.\n",
    "\n",
    "- __Practical Application__: Through exercises, you applied these concepts to clean data by remapping categories in a DataFrame. You used the extract function from __thefuzz__ to compare a string against an array of strings, identifying matches with a similarity score above a certain threshold to consolidate typos or variations into correct categories.\n",
    "\n",
    "For example, to compare the similarity between \"reading\" and its typo using __thefuzz__, you would use:\n",
    "\n",
    "  - ___from thefuzz import fuzz___\n",
    "  - ___similarity_score = fuzz.WRatio('reading', 'raeding')___\n",
    "This lesson equipped you with the tools to improve data quality by addressing inconsistencies in textual data, setting the stage for more advanced record linkage techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>cuisine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, addr, city, phone, cuisine_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.rename(columns={'type': 'cuisine_type'}, inplace=True)\n",
    "restaurants.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instantiate a comparison object using the __recordlinkage.Compare()__ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the appropriate __comp_cl__ method to find exact matches between the __city__ and __cuisine_type__ columns of both DataFrames.\n",
    "- Use the appropriate __comp_cl__ method to find similar strings with a __0.8__ similarity threshold in the __rest_name__ column of both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches on city, cuisine_types\n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('cuisine_type', 'cuisine_type', label='cuisine_type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('name', 'name', label='name', threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your pairs have been generated and stored in pairs, you will find exact matches in the city and cuisine_type columns between each pair, and similar strings for each pair in the rest_name column. Both DataFrames, pandas and recordlinkage are in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For this example, tightening your selection criteria will ensure good duplicate finds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Understanding Record Linkage__: You discovered that record linkage is the method used to combine data from different sources by identifying and linking records that refer to the same entity across datasets. This is particularly useful when datasets have fuzzy duplicate values that a regular join can't merge.\n",
    "\n",
    "- __Generating Pairs with Blocking__: You learned how to generate pairs of potentially matching records between two DataFrames. To manage scalability and efficiency, especially with large datasets, you applied the concept of blocking. Blocking reduces the number of comparisons needed by only generating pairs that match on a specified column, such as the state column in our example.\n",
    "\n",
    "- __Using the recordlinkage Package__: You explored how to use the recordlinkage package to perform these tasks. For instance, to generate pairs blocked by state, you used:\n",
    "\n",
    "  - ___import recordlinkage___\n",
    "  - indexer = recordlinkage.Index()\n",
    "  - __indexer.block('state')__\n",
    "  - __pairs = indexer.index(census_A, census_B)__\n",
    "\n",
    "This code snippet creates an indexing object to generate pairs, significantly reducing the potential pairs to a manageable number by focusing on those that share the same state.\n",
    "\n",
    "- __Comparing Records__: After generating pairs, you learned how to compare them to find potential matches. You used exact matches for some columns and computed string similarities for others, employing methods like .exact() and .string() from the recordlinkage package. This step is crucial for identifying which records across the datasets refer to the same entities.\n",
    "\n",
    "- __Filtering Matches__: Finally, you discovered how to filter these comparisons to identify true matches based on a threshold, preparing you for the next steps in linking the records to create a unified dataset.\n",
    "\n",
    "This lesson equipped you with the foundational skills to start merging datasets with record linkage, setting the stage for more advanced techniques in data preparation and cleaning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
