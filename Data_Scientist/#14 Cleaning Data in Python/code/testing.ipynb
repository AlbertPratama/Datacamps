{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curah_hujan</th>\n",
       "      <th>site</th>\n",
       "      <th>debit_air</th>\n",
       "      <th>tinggi_muka_air</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>Bukit Duri</td>\n",
       "      <td>100</td>\n",
       "      <td>220</td>\n",
       "      <td>Darurat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>Katulampa</td>\n",
       "      <td>220</td>\n",
       "      <td>180</td>\n",
       "      <td>Darurat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Bukit Duri</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>Siaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>Beji</td>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>Siaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>Beji</td>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>Darurat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>190</td>\n",
       "      <td>Katulampa</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>Darurat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   curah_hujan        site  debit_air  tinggi_muka_air   status\n",
       "0          150  Bukit Duri        100              220  Darurat\n",
       "1           90   Katulampa        220              180  Darurat\n",
       "2          100  Bukit Duri        200              150    Siaga\n",
       "3          200        Beji        200              130    Siaga\n",
       "4          150        Beji        100              180  Darurat\n",
       "5          190   Katulampa        210              150  Darurat"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "arr = [\n",
    "    [150, 'Bukit Duri', 100, 220, 'Darurat'],\n",
    "    [90, 'Katulampa', 220, 180, 'Darurat'],\n",
    "    [100, 'Bukit Duri', 200, 150, 'Siaga'],\n",
    "    [200, 'Beji', 200, 130, 'Siaga'],\n",
    "    [150, 'Beji', 100, 180, 'Darurat'],\n",
    "    [190, 'Katulampa', 210, 150, 'Darurat'],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(arr)\n",
    "df.columns = ['curah_hujan', 'site', 'debit_air', 'tinggi_muka_air', 'status']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LOC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curah_hujan</th>\n",
       "      <th>site</th>\n",
       "      <th>debit_air</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>Katulampa</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Bukit Duri</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>Beji</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>Beji</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   curah_hujan        site  debit_air\n",
       "1           90   Katulampa        220\n",
       "2          100  Bukit Duri        200\n",
       "3          200        Beji        200\n",
       "4          150        Beji        100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1:4, 'curah_hujan':'debit_air']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ILOC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curah_hujan</th>\n",
       "      <th>site</th>\n",
       "      <th>debit_air</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>Katulampa</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Bukit Duri</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>Beji</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>Beji</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   curah_hujan        site  debit_air\n",
       "1           90   Katulampa        220\n",
       "2          100  Bukit Duri        200\n",
       "3          200        Beji        200\n",
       "4          150        Beji        100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1:5, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 8, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "today_date = dt.date.today()\n",
    "today_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Albert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Albert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Albert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Albert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Albert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Melodie Stuart', 'Dominic Shannon', 'Quintessa Tillman', 'Dr. Christine Nicholson', 'Regina Clements']\n"
     ]
    }
   ],
   "source": [
    "# Data awal sebagai string\n",
    "data = \"\"\"Melodie Stuart\n",
    "Dominic Shannon\n",
    "Quintessa Tillman\n",
    "Dr. Christine Nicholson\n",
    "Regina Clements\n",
    "\"\"\"\n",
    "\n",
    "# Memisahkan data menjadi daftar nama berdasarkan newline\n",
    "names = data.splitlines()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Menambahkan koma di akhir setiap nama\n",
    "# names_with_comma = [name + \",\" for name in names]\n",
    "\n",
    "# # Menggabungkan kembali daftar menjadi string dengan newline\n",
    "# final_data = \"\\n\".join(names_with_comma)\n",
    "\n",
    "# # Menampilkan hasilnya\n",
    "# print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hell = pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "      <td>Melodie Stuart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Dominic Shannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "      <td>Quintessa Tillman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Somewhat dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Somewhat unsatisfied</td>\n",
       "      <td>Dr. Christine Nicholson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty</td>\n",
       "      <td>Somewhat unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "      <td>Regina Clements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cleanliness           safety          satisfaction  \\\n",
       "0           Clean          Neutral        Very satisfied   \n",
       "1         Average        Very safe               Neutral   \n",
       "2  Somewhat clean    Somewhat safe    Somewhat satisfied   \n",
       "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied   \n",
       "4           Dirty  Somewhat unsafe      Very unsatisfied   \n",
       "\n",
       "                 full_name  \n",
       "0           Melodie Stuart  \n",
       "1          Dominic Shannon  \n",
       "2        Quintessa Tillman  \n",
       "3  Dr. Christine Nicholson  \n",
       "4          Regina Clements  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'cleanliness': ['Clean', 'Average', 'Somewhat clean', 'Somewhat dirty', 'Dirty'],\n",
    "    'safety': ['Neutral', 'Very safe', 'Somewhat safe', 'Very unsafe', 'Somewhat unsafe'],\n",
    "    'satisfaction': ['Very satisfied', 'Neutral', 'Somewhat satisfied', 'Somewhat unsatisfied', 'Very unsatisfied'],\n",
    "    'full_name': names\n",
    "}\n",
    "\n",
    "categories = pd.DataFrame(data)\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "      <td>Melodie Stuart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Dominic Shannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "      <td>Quintessa Tillman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Somewhat dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Somewhat unsatisfied</td>\n",
       "      <td>Dr. Christine Nicholson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty</td>\n",
       "      <td>Somewhat unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "      <td>Regina Clements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cleanliness           safety          satisfaction  \\\n",
       "0           Clean          Neutral        Very satisfied   \n",
       "1         Average        Very safe               Neutral   \n",
       "2  Somewhat clean    Somewhat safe    Somewhat satisfied   \n",
       "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied   \n",
       "4           Dirty  Somewhat unsafe      Very unsatisfied   \n",
       "\n",
       "                 full_name  \n",
       "0           Melodie Stuart  \n",
       "1          Dominic Shannon  \n",
       "2        Quintessa Tillman  \n",
       "3  Dr. Christine Nicholson  \n",
       "4          Regina Clements  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name = \"\"\"Melodie Stuart\n",
    "Dominic Shannon\n",
    "Quintessa Tillman\n",
    "Dr. Christine Nicholson\n",
    "Regina Clements\n",
    "Colleen Harding\n",
    "Kaitlin Cochran\n",
    "Molly Norton\n",
    "Richard Lott\n",
    "Matthew Nguyen\n",
    "Dr. Laith Decker\n",
    "Holly Austin\n",
    "Jaden Gray\n",
    "Germaine Hurley\n",
    "Kyle Gay\n",
    "Zachery Diaz\n",
    "Carolyn Hartman\n",
    "Miss Alana Grant\n",
    "Idola Acosta\n",
    "Dara English\n",
    "Miss Aurora Flores\n",
    "Henry Sloan\n",
    "Jared Chase\n",
    "Xavier Castro\n",
    "Holmes Fowler\n",
    "Lucy Noel\n",
    "Kerry Tucker\n",
    "Garrison Barrett\n",
    "Stephanie Cannon\n",
    "Dr. Charlotte Savage\n",
    "Lane Clements\n",
    "Aimee Whitfield\n",
    "Martena Neal\n",
    "Xandra Hartman\n",
    "Meredith Gutierrez\n",
    "Mr. Kermit Deleon\n",
    "Derek Terrell\n",
    "Shaeleigh Mccarthy\n",
    "Burke Leon\n",
    "Mr. Clinton Holmes\n",
    "Whoopi Tillman\n",
    "Hamilton Gardner\n",
    "Graiden Bridges\n",
    "Sheila Robinson\n",
    "Cameron Barlow\n",
    "Kasimir Irwin\n",
    "Ms. Lilah Chen\n",
    "Judith Price\n",
    "Dane Barker\n",
    "Micah Bullock\n",
    "Leonard Stevens\n",
    "Ms. Beverly Hampton\n",
    "Devin Morrison\n",
    "Mr. Jordan Cooke\n",
    "Miss Ann Hale\n",
    "Graiden Riddle\n",
    "Julian Stanley\n",
    "Christine Carter\n",
    "Hasad Valentine\n",
    "Bevis Mcdowell\n",
    "Alec Davis\n",
    "Dr. Daniel Hood\n",
    "Ms. Britanney Schmidt\n",
    "Wanda Jackson\n",
    "Quyn Henderson\n",
    "Hammett Duncan\n",
    "Duncan Stark\n",
    "Jin Shannon\n",
    "Fulton Meadows\n",
    "Dr. Malik Hanson\n",
    "Laith Espinoza\n",
    "Dr. Jared Holman\n",
    "Julie Davidson\n",
    "Dr. Jane Harrell\n",
    "Aphrodite Shannon\n",
    "Jermaine Randall\n",
    "Hammett Talley\n",
    "Sasha Riggs\n",
    "Dr. Damian Wynn\n",
    "Aidan Macias\n",
    "Sawyer Hines\n",
    "Mr. Hector Caldwell\n",
    "Abra Webb\n",
    "Stone Price\n",
    "Cheyenne Stout\n",
    "Lareina Wall\n",
    "Dr. Ella Pena\n",
    "Quintessa Sherman\n",
    "Ishmael Duffy\n",
    "Ms. Willa Stuart\n",
    "Gareth Hunt\n",
    "Stewart Jacobs\n",
    "Ms. Amaya Pate\n",
    "Dr. Xavier Medina\n",
    "Mr. Marvin Mcneil\n",
    "Imogene Harris\n",
    "Abbot Hensley\n",
    "Miss Fiona Velez\n",
    "Rinah Stephenson\n",
    "Ms. Olivia Keith\n",
    "Vielka Rosario\n",
    "Lani Sawyer\n",
    "Clayton Sparks\n",
    "Oprah Ingram\n",
    "Acton Smith\n",
    "Demetria Byrd\n",
    "Patience Galloway\n",
    "Hoyt Alvarez\n",
    "Dara Pennington\n",
    "Ebony Davidson\n",
    "Brent Rosario\n",
    "Melyssa Mayer\n",
    "Regan Kelly\n",
    "Leah Barlow\n",
    "Nathan Santos\n",
    "Uta Mckee\n",
    "Lawrence Gallegos\n",
    "Matthew Edwards\n",
    "Xander Wilson\n",
    "Kelly Pittman\n",
    "Brynne Pugh\n",
    "Shea Collins\n",
    "Hu Carver\n",
    "Stacey Coleman\n",
    "Kaye Mcgowan\n",
    "Vivien Cobb\n",
    "Vaughan Harrison\n",
    "Porter Hudson\n",
    "Carl Conway\n",
    "Lyle Bradshaw\n",
    "Hashim Walter\n",
    "Branden Larson\n",
    "Idola Ball\n",
    "Camilla White\n",
    "Rafael Lowery\n",
    "Victor Leon\n",
    "Yasir Lynch\n",
    "Dr. Emerson Woodard\n",
    "Dr. Astra Mcneil\n",
    "Dr. Shafira Marks\n",
    "Mr. Dominic Smith\n",
    "Talon Holder\n",
    "Ivor Wise\n",
    "Carolyn Clay\n",
    "Jerome Ruiz\n",
    "Todd Chase\n",
    "Gray Noel\n",
    "Ann Sanchez\n",
    "Mr. Alec Heath\n",
    "Heidi Terry\n",
    "Alana Velasquez\n",
    "Mr. Jared York\n",
    "Abbot Lester\n",
    "Dr. Fulton Turner\n",
    "Dr. Maggie Cortez\n",
    "Ramona Wade\n",
    "Dr. Lynn Thomas\n",
    "Aquila Graham\n",
    "Gareth Marks\n",
    "Dolan Wolf\n",
    "Julie Coffey\n",
    "Emerson Hatfield\n",
    "Claire Rios\n",
    "Christian Doyle\n",
    "Haley Oliver\n",
    "Rigel Day\n",
    "Clare Gould\n",
    "Ms. Keiko Mcfarland\n",
    "Duncan Chandler\n",
    "Penelope Stark\n",
    "Kasper Shields\n",
    "Dr. Rose Fleming\n",
    "Miss Petra Mitchell\n",
    "Ms. Regan Lynch\n",
    "Keane Bennett\n",
    "Nash Head\n",
    "Ainsley Riley\n",
    "Kirestin Newton\n",
    "Jakeem Hall\n",
    "Reece Mitchell\n",
    "Wanda Walls\n",
    "Barry Mccray\n",
    "Dr. Zahir Hardin\n",
    "Graiden Cox\n",
    "Miss Lara Green\n",
    "Felix Bell\n",
    "Mr. Addison Day\n",
    "Tallulah Guzman\n",
    "Jocelyn Guzman\n",
    "Ivory Miller\n",
    "Mr. Eaton Vazquez\n",
    "Silas Clemons\n",
    "Quinn Barry\n",
    "Orson Pratt\n",
    "Constance Morse\n",
    "Ms. Vanna Rivera\n",
    "Miss Venus Lowe\n",
    "Amethyst Nieves\n",
    "Miss Vivian Foreman\n",
    "Miss Wendy Griffin\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Melodie Stuart', 'Dominic Shannon', 'Quintessa Tillman', 'Dr. Christine Nicholson', 'Regina Clements', 'Colleen Harding', 'Kaitlin Cochran', 'Molly Norton', 'Richard Lott', 'Matthew Nguyen', 'Dr. Laith Decker', 'Holly Austin', 'Jaden Gray', 'Germaine Hurley', 'Kyle Gay', 'Zachery Diaz', 'Carolyn Hartman', 'Miss Alana Grant', 'Idola Acosta', 'Dara English', 'Miss Aurora Flores', 'Henry Sloan', 'Jared Chase', 'Xavier Castro', 'Holmes Fowler', 'Lucy Noel', 'Kerry Tucker', 'Garrison Barrett', 'Stephanie Cannon', 'Dr. Charlotte Savage', 'Lane Clements', 'Aimee Whitfield', 'Martena Neal', 'Xandra Hartman', 'Meredith Gutierrez', 'Mr. Kermit Deleon', 'Derek Terrell', 'Shaeleigh Mccarthy', 'Burke Leon', 'Mr. Clinton Holmes', 'Whoopi Tillman', 'Hamilton Gardner', 'Graiden Bridges', 'Sheila Robinson', 'Cameron Barlow', 'Kasimir Irwin', 'Ms. Lilah Chen', 'Judith Price', 'Dane Barker', 'Micah Bullock', 'Leonard Stevens', 'Ms. Beverly Hampton', 'Devin Morrison', 'Mr. Jordan Cooke', 'Miss Ann Hale', 'Graiden Riddle', 'Julian Stanley', 'Christine Carter', 'Hasad Valentine', 'Bevis Mcdowell', 'Alec Davis', 'Dr. Daniel Hood', 'Ms. Britanney Schmidt', 'Wanda Jackson', 'Quyn Henderson', 'Hammett Duncan', 'Duncan Stark', 'Jin Shannon', 'Fulton Meadows', 'Dr. Malik Hanson', 'Laith Espinoza', 'Dr. Jared Holman', 'Julie Davidson', 'Dr. Jane Harrell', 'Aphrodite Shannon', 'Jermaine Randall', 'Hammett Talley', 'Sasha Riggs', 'Dr. Damian Wynn', 'Aidan Macias', 'Sawyer Hines', 'Mr. Hector Caldwell', 'Abra Webb', 'Stone Price', 'Cheyenne Stout', 'Lareina Wall', 'Dr. Ella Pena', 'Quintessa Sherman', 'Ishmael Duffy', 'Ms. Willa Stuart', 'Gareth Hunt', 'Stewart Jacobs', 'Ms. Amaya Pate', 'Dr. Xavier Medina', 'Mr. Marvin Mcneil', 'Imogene Harris', 'Abbot Hensley', 'Miss Fiona Velez', 'Rinah Stephenson', 'Ms. Olivia Keith', 'Vielka Rosario', 'Lani Sawyer', 'Clayton Sparks', 'Oprah Ingram', 'Acton Smith', 'Demetria Byrd', 'Patience Galloway', 'Hoyt Alvarez', 'Dara Pennington', 'Ebony Davidson', 'Brent Rosario', 'Melyssa Mayer', 'Regan Kelly', 'Leah Barlow', 'Nathan Santos', 'Uta Mckee', 'Lawrence Gallegos', 'Matthew Edwards', 'Xander Wilson', 'Kelly Pittman', 'Brynne Pugh', 'Shea Collins', 'Hu Carver', 'Stacey Coleman', 'Kaye Mcgowan', 'Vivien Cobb', 'Vaughan Harrison', 'Porter Hudson', 'Carl Conway', 'Lyle Bradshaw', 'Hashim Walter', 'Branden Larson', 'Idola Ball', 'Camilla White', 'Rafael Lowery', 'Victor Leon', 'Yasir Lynch', 'Dr. Emerson Woodard', 'Dr. Astra Mcneil', 'Dr. Shafira Marks', 'Mr. Dominic Smith', 'Talon Holder', 'Ivor Wise', 'Carolyn Clay', 'Jerome Ruiz', 'Todd Chase', 'Gray Noel', 'Ann Sanchez', 'Mr. Alec Heath', 'Heidi Terry', 'Alana Velasquez', 'Mr. Jared York', 'Abbot Lester', 'Dr. Fulton Turner', 'Dr. Maggie Cortez', 'Ramona Wade', 'Dr. Lynn Thomas', 'Aquila Graham', 'Gareth Marks', 'Dolan Wolf', 'Julie Coffey', 'Emerson Hatfield', 'Claire Rios', 'Christian Doyle', 'Haley Oliver', 'Rigel Day', 'Clare Gould', 'Ms. Keiko Mcfarland', 'Duncan Chandler', 'Penelope Stark', 'Kasper Shields', 'Dr. Rose Fleming', 'Miss Petra Mitchell', 'Ms. Regan Lynch', 'Keane Bennett', 'Nash Head', 'Ainsley Riley', 'Kirestin Newton', 'Jakeem Hall', 'Reece Mitchell', 'Wanda Walls', 'Barry Mccray', 'Dr. Zahir Hardin', 'Graiden Cox', 'Miss Lara Green', 'Felix Bell', 'Mr. Addison Day', 'Tallulah Guzman', 'Jocelyn Guzman', 'Ivory Miller', 'Mr. Eaton Vazquez', 'Silas Clemons', 'Quinn Barry', 'Orson Pratt', 'Constance Morse', 'Ms. Vanna Rivera', 'Miss Venus Lowe', 'Amethyst Nieves', 'Miss Vivian Foreman', 'Miss Wendy Griffin']\n"
     ]
    }
   ],
   "source": [
    "full_name = full_name.splitlines()\n",
    "\n",
    "print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# np.save('full_name.npy', full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_response = \"\"\"It was terrible\n",
    "I didn't like the flight\n",
    "I hate this\n",
    "Not a fan\n",
    "Bad\n",
    "Horrible\n",
    "Very poor\n",
    "Unacceptable flight\n",
    "It was awful\n",
    "My fllight was really unpleasant\n",
    "I am not a fan\n",
    "I had a bad flight\n",
    "It was very bad\n",
    "it was horrible\n",
    "Terrible\n",
    "It was substandard\n",
    "I did not enjoy the flight\n",
    "The airport personnell forgot to alert us of delayed flights, the bathrooms could have been cleaner\n",
    "The food in the airport was really really expensive - also no automatic escalators!\n",
    "One of the other travelers was really loud and talkative and was making a scene and no one did anything about it\n",
    "I don't remember answering the survey with these scores, my experience was great!\n",
    "The airport personnel kept ignoring my requests for directions\n",
    "The chair I sat in was extremely uncomfortable, I still have back pain to this day!\n",
    "I wish you were more like other airports, the flights were really disorganized!\n",
    "I was really unsatisfied with the wait times before the flight. It was unacceptable.\n",
    "The flight was okay, but I didn't really like the number of times I had to stop at security\n",
    "We were really slowed down by security measures, I missed my flight because of it!\n",
    "There was a spill on the aisle next to the bathroom and it took hours to clean!\n",
    "I felt very unsatisfied by how long the flight took to take off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was terrible',\n",
       " \"I didn't like the flight\",\n",
       " 'I hate this',\n",
       " 'Not a fan',\n",
       " 'Bad',\n",
       " 'Horrible',\n",
       " 'Very poor',\n",
       " 'Unacceptable flight',\n",
       " 'It was awful',\n",
       " 'My fllight was really unpleasant',\n",
       " 'I am not a fan',\n",
       " 'I had a bad flight',\n",
       " 'It was very bad',\n",
       " 'it was horrible',\n",
       " 'Terrible',\n",
       " 'It was substandard',\n",
       " 'I did not enjoy the flight',\n",
       " 'The airport personnell forgot to alert us of delayed flights, the bathrooms could have been cleaner',\n",
       " 'The food in the airport was really really expensive - also no automatic escalators!',\n",
       " 'One of the other travelers was really loud and talkative and was making a scene and no one did anything about it',\n",
       " \"I don't remember answering the survey with these scores, my experience was great!\",\n",
       " 'The airport personnel kept ignoring my requests for directions',\n",
       " 'The chair I sat in was extremely uncomfortable, I still have back pain to this day!',\n",
       " 'I wish you were more like other airports, the flights were really disorganized!',\n",
       " 'I was really unsatisfied with the wait times before the flight. It was unacceptable.',\n",
       " \"The flight was okay, but I didn't really like the number of times I had to stop at security\",\n",
       " 'We were really slowed down by security measures, I missed my flight because of it!',\n",
       " 'There was a spill on the aisle next to the bathroom and it took hours to clean!',\n",
       " 'I felt very unsatisfied by how long the flight took to take off.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_response = survey_response.splitlines()\n",
    "survey_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('survey_response.npy', survey_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_cur = \"\"\"dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "euro\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "euro\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "euro\n",
    "euro\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "euro\n",
    "euro\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "euro\n",
    "euro\n",
    "euro\n",
    "dollar\n",
    "euro\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "dollar\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'euro',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar',\n",
       " 'dollar']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acct_cur = acct_cur.splitlines()\n",
    "acct_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('acct_cur.npy', acct_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = \"\"\"62\n",
    "62\n",
    "34\n",
    "39\n",
    "40\n",
    "44\n",
    "53\n",
    "61\n",
    "49\n",
    "59\n",
    "42\n",
    "58\n",
    "40\n",
    "49\n",
    "46\n",
    "53\n",
    "46\n",
    "41\n",
    "59\n",
    "31\n",
    "62\n",
    "62\n",
    "32\n",
    "56\n",
    "32\n",
    "40\n",
    "32\n",
    "43\n",
    "35\n",
    "35\n",
    "57\n",
    "37\n",
    "63\n",
    "43\n",
    "38\n",
    "31\n",
    "40\n",
    "62\n",
    "35\n",
    "52\n",
    "51\n",
    "50\n",
    "41\n",
    "54\n",
    "32\n",
    "49\n",
    "35\n",
    "62\n",
    "61\n",
    "63\n",
    "45\n",
    "53\n",
    "46\n",
    "32\n",
    "36\n",
    "33\n",
    "52\n",
    "50\n",
    "54\n",
    "56\n",
    "52\n",
    "49\n",
    "33\n",
    "49\n",
    "42\n",
    "58\n",
    "41\n",
    "34\n",
    "57\n",
    "32\n",
    "36\n",
    "55\n",
    "52\n",
    "50\n",
    "37\n",
    "50\n",
    "48\n",
    "44\n",
    "50\n",
    "52\n",
    "54\n",
    "33\n",
    "51\n",
    "61\n",
    "51\n",
    "50\n",
    "50\n",
    "56\n",
    "57\n",
    "56\n",
    "40\n",
    "50\n",
    "34\n",
    "61\n",
    "63\n",
    "50\n",
    "35\n",
    "40\n",
    "55\n",
    "31\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['62',\n",
       " '62',\n",
       " '34',\n",
       " '39',\n",
       " '40',\n",
       " '44',\n",
       " '53',\n",
       " '61',\n",
       " '49',\n",
       " '59',\n",
       " '42',\n",
       " '58',\n",
       " '40',\n",
       " '49',\n",
       " '46',\n",
       " '53',\n",
       " '46',\n",
       " '41',\n",
       " '59',\n",
       " '31',\n",
       " '62',\n",
       " '62',\n",
       " '32',\n",
       " '56',\n",
       " '32',\n",
       " '40',\n",
       " '32',\n",
       " '43',\n",
       " '35',\n",
       " '35',\n",
       " '57',\n",
       " '37',\n",
       " '63',\n",
       " '43',\n",
       " '38',\n",
       " '31',\n",
       " '40',\n",
       " '62',\n",
       " '35',\n",
       " '52',\n",
       " '51',\n",
       " '50',\n",
       " '41',\n",
       " '54',\n",
       " '32',\n",
       " '49',\n",
       " '35',\n",
       " '62',\n",
       " '61',\n",
       " '63',\n",
       " '45',\n",
       " '53',\n",
       " '46',\n",
       " '32',\n",
       " '36',\n",
       " '33',\n",
       " '52',\n",
       " '50',\n",
       " '54',\n",
       " '56',\n",
       " '52',\n",
       " '49',\n",
       " '33',\n",
       " '49',\n",
       " '42',\n",
       " '58',\n",
       " '41',\n",
       " '34',\n",
       " '57',\n",
       " '32',\n",
       " '36',\n",
       " '55',\n",
       " '52',\n",
       " '50',\n",
       " '37',\n",
       " '50',\n",
       " '48',\n",
       " '44',\n",
       " '50',\n",
       " '52',\n",
       " '54',\n",
       " '33',\n",
       " '51',\n",
       " '61',\n",
       " '51',\n",
       " '50',\n",
       " '50',\n",
       " '56',\n",
       " '57',\n",
       " '56',\n",
       " '40',\n",
       " '50',\n",
       " '34',\n",
       " '61',\n",
       " '63',\n",
       " '50',\n",
       " '35',\n",
       " '40',\n",
       " '55',\n",
       " '31']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = age.splitlines()\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.save('age.npy', age)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
